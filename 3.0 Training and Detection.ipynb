{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a string variable that will hold the name of our custom model\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "\n",
    "# This is a string variable that holds the name of the pretrained model we will use as a starting point\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "\n",
    "# This is a string variable that holds the URL to download the pretrained model from\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# This is a string variable that holds the name of the script used to generate TensorFlow records from the dataset\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "\n",
    "# This is a string variable that holds the name of the label map file that maps object class names to integer IDs\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maps names to directory\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dictionary that maps file names to their file paths\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop checks if each path in the `paths` dictionary exists, and creates it if it doesn't\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        # If the operating system is POSIX (e.g. Linux or MacOS), create the directory using the 'mkdir -p' command\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        # If the operating system is Windows, create the directory using the 'mkdir' command\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Download TF Models Pretrained Models from Tensorflow Model Zoo and install TFOD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code clones the TensorFlow models repository if it doesn't already exist\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    # If the research/object_detection directory does not exist in the APIMODEL_PATH directory, clone the TensorFlow models repository using `git`\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) moved.\n",
      "        1 file(s) copied.\n",
      "running build\n",
      "running build_py\n",
      "copying object_detection\\protos\\anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\argmax_matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\bipartite_matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\box_predictor_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\calibration_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\center_net_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\eval_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\faster_rcnn_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\faster_rcnn_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\flexible_grid_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\fpn_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\graph_rewriter_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\grid_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\hyperparams_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\image_resizer_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\input_reader_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\keypoint_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\losses_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\matcher_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\mean_stddev_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\model_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\multiscale_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\optimizer_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\pipeline_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\post_processing_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\preprocessor_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\region_similarity_calculator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\square_box_coder_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\ssd_anchor_generator_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\ssd_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\string_int_label_map_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\target_assigner_pb2.py -> build\\lib\\object_detection\\protos\n",
      "copying object_detection\\protos\\train_pb2.py -> build\\lib\\object_detection\\protos\n",
      "running egg_info\n",
      "writing object_detection.egg-info\\PKG-INFO\n",
      "writing dependency_links to object_detection.egg-info\\dependency_links.txt\n",
      "writing requirements to object_detection.egg-info\\requires.txt\n",
      "writing top-level names to object_detection.egg-info\\top_level.txt\n",
      "reading manifest file 'object_detection.egg-info\\SOURCES.txt'\n",
      "writing manifest file 'object_detection.egg-info\\SOURCES.txt'\n",
      "running install\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ds-c-tfod-01\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ds-c-tfod-01\\lib\\site-packages\\setuptools\\command\\easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "error: can't create or remove files in install directory\n",
      "\n",
      "The following error occurred while trying to add or remove files in the\n",
      "installation directory:\n",
      "\n",
      "    [Errno 13] Permission denied: 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\ds-c-tfod-01\\\\Lib\\\\site-packages\\\\test-easy-install-19060.write-test'\n",
      "\n",
      "The installation directory you specified (via --install-dir, --prefix, or\n",
      "the distutils default setting) was:\n",
      "\n",
      "    C:\\ProgramData\\Anaconda3\\envs\\ds-c-tfod-01\\Lib\\site-packages\\\n",
      "\n",
      "Perhaps your account does not have write access to this directory?  If the\n",
      "installation directory is a system-owned directory, you may need to sign in\n",
      "as the administrator or \"root\" account.  If you do not have administrative\n",
      "access to this machine, you may wish to choose a different installation\n",
      "directory, preferably one that is listed in your PYTHONPATH environment\n",
      "variable.\n",
      "\n",
      "For information on other options, you may wish to consult the\n",
      "documentation at:\n",
      "\n",
      "  https://setuptools.pypa.io/en/latest/deprecated/easy_install.html\n",
      "\n",
      "Please make the appropriate changes for your system and try again.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///E:/DS/tfod-01/Tensortflow_object_detection-01/Tensorflow/models/research/slim\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\ds-c-tfod-01\\lib\\site-packages (from slim==0.1) (1.16.0)\n",
      "Requirement already satisfied: tf-slim>=1.1 in c:\\users\\imran\\appdata\\roaming\\python\\python38\\site-packages (from slim==0.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\programdata\\anaconda3\\envs\\ds-c-tfod-01\\lib\\site-packages (from tf-slim>=1.1->slim==0.1) (1.3.0)\n",
      "Installing collected packages: slim\n",
      "  Attempting uninstall: slim\n",
      "    Found existing installation: slim 0.1\n",
      "    Uninstalling slim-0.1:\n",
      "      Successfully uninstalled slim-0.1\n",
      "  Running setup.py develop for slim\n",
      "Successfully installed slim\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tests under Python 3.8.16: C:\\ProgramData\\Anaconda3\\envs\\ds-c-tfod-01\\python.exe\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2023-03-19 16:03:21.771853: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 16:03:22.166325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "C:\\Users\\Imran\\AppData\\Roaming\\Python\\Python38\\site-packages\\object_detection-0.1-py3.8.egg\\object_detection\\builders\\model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0319 16:03:22.719406 29368 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.13s\n",
      "I0319 16:03:22.894443 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.13s\n",
      "I0319 16:03:24.026433 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "I0319 16:03:24.211296 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
      "I0319 16:03:24.461474 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.31s\n",
      "I0319 16:03:25.776166 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.31s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0319 16:03:25.780499 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0319 16:03:25.797937 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0319 16:03:25.809021 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0319 16:03:25.820153 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "I0319 16:03:25.886797 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "I0319 16:03:25.947828 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "I0319 16:03:26.014422 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
      "I0319 16:03:26.079028 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
      "I0319 16:03:26.141497 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0319 16:03:26.162182 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0319 16:03:26.285967 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0319 16:03:26.286965 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
      "I0319 16:03:26.286965 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
      "I0319 16:03:26.287966 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:26.309554 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:26.309554 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:26.359394 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:26.360398 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:26.488242 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:26.488242 29368 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0319 16:03:26.609931 29368 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0319 16:03:26.609931 29368 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0319 16:03:26.786586 29368 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0319 16:03:26.786586 29368 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0319 16:03:27.075487 29368 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0319 16:03:27.075487 29368 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0319 16:03:27.331846 29368 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0319 16:03:27.331846 29368 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0319 16:03:27.396993 29368 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0319 16:03:27.428012 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:27.469732 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0319 16:03:27.470731 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
      "I0319 16:03:27.470731 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
      "I0319 16:03:27.471732 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:27.483282 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:27.483282 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:27.578610 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:27.578610 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:27.742536 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:27.742536 29368 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0319 16:03:27.908479 29368 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I0319 16:03:27.909502 29368 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0319 16:03:28.128570 29368 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I0319 16:03:28.128570 29368 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0319 16:03:28.350410 29368 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I0319 16:03:28.350410 29368 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0319 16:03:28.644079 29368 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I0319 16:03:28.644079 29368 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I0319 16:03:28.772341 29368 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I0319 16:03:28.791440 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:28.835633 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0319 16:03:28.835633 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
      "I0319 16:03:28.835633 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
      "I0319 16:03:28.837634 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:28.848658 29368 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I0319 16:03:28.848658 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:28.934709 29368 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I0319 16:03:28.934709 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:29.099565 29368 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I0319 16:03:29.099565 29368 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0319 16:03:29.273681 29368 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0319 16:03:29.273681 29368 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0319 16:03:29.511482 29368 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I0319 16:03:29.511482 29368 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0319 16:03:29.749020 29368 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I0319 16:03:29.749020 29368 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0319 16:03:30.042808 29368 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I0319 16:03:30.042808 29368 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I0319 16:03:30.164157 29368 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I0319 16:03:30.188756 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:30.232605 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0319 16:03:30.233606 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
      "I0319 16:03:30.233606 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
      "I0319 16:03:30.234607 29368 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0319 16:03:30.247920 29368 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I0319 16:03:30.247920 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:30.343092 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:30.343092 29368 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0319 16:03:30.645026 29368 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0319 16:03:30.645026 29368 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0319 16:03:30.815424 29368 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I0319 16:03:30.815424 29368 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0319 16:03:31.114971 29368 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I0319 16:03:31.114971 29368 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0319 16:03:31.405574 29368 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I0319 16:03:31.406574 29368 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0319 16:03:31.758393 29368 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I0319 16:03:31.758393 29368 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I0319 16:03:31.878842 29368 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I0319 16:03:31.905420 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:31.951182 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0319 16:03:31.951182 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
      "I0319 16:03:31.951182 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
      "I0319 16:03:31.952181 29368 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0319 16:03:31.966329 29368 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0319 16:03:31.966329 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:32.057226 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:32.057226 29368 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0319 16:03:32.287837 29368 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I0319 16:03:32.287837 29368 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0319 16:03:32.549612 29368 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I0319 16:03:32.549612 29368 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0319 16:03:32.890918 29368 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I0319 16:03:32.890918 29368 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0319 16:03:33.236014 29368 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I0319 16:03:33.236014 29368 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0319 16:03:33.713866 29368 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I0319 16:03:33.713866 29368 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I0319 16:03:33.849463 29368 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I0319 16:03:33.873759 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:33.928868 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0319 16:03:33.928868 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
      "I0319 16:03:33.928868 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
      "I0319 16:03:33.929866 29368 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0319 16:03:33.943075 29368 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I0319 16:03:33.943075 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:34.076300 29368 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I0319 16:03:34.076300 29368 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0319 16:03:34.361328 29368 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0319 16:03:34.361328 29368 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0319 16:03:34.789761 29368 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I0319 16:03:34.789761 29368 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0319 16:03:35.198219 29368 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I0319 16:03:35.198219 29368 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0319 16:03:35.604168 29368 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I0319 16:03:35.604168 29368 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0319 16:03:36.121855 29368 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I0319 16:03:36.121855 29368 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I0319 16:03:36.299950 29368 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I0319 16:03:36.326199 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:36.390454 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0319 16:03:36.390454 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
      "I0319 16:03:36.390454 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
      "I0319 16:03:36.391463 29368 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0319 16:03:36.405074 29368 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I0319 16:03:36.405074 29368 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0319 16:03:36.542416 29368 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0319 16:03:36.542416 29368 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0319 16:03:36.879275 29368 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I0319 16:03:36.879275 29368 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0319 16:03:37.232133 29368 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I0319 16:03:37.232133 29368 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0319 16:03:37.718962 29368 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I0319 16:03:37.718962 29368 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0319 16:03:38.184339 29368 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I0319 16:03:38.185347 29368 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0319 16:03:38.823911 29368 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I0319 16:03:38.823911 29368 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I0319 16:03:39.001879 29368 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I0319 16:03:39.023937 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0319 16:03:39.254928 29368 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0319 16:03:39.254928 29368 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
      "I0319 16:03:39.254928 29368 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
      "I0319 16:03:39.255927 29368 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0319 16:03:39.268480 29368 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I0319 16:03:39.268480 29368 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0319 16:03:39.451225 29368 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I0319 16:03:39.451225 29368 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0319 16:03:39.840417 29368 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I0319 16:03:39.840417 29368 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0319 16:03:40.235454 29368 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I0319 16:03:40.235454 29368 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0319 16:03:40.801563 29368 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I0319 16:03:40.801563 29368 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0319 16:03:41.373857 29368 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I0319 16:03:41.373857 29368 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0319 16:03:42.097849 29368 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I0319 16:03:42.098849 29368 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I0319 16:03:42.347584 29368 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I0319 16:03:42.379602 29368 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.32s\n",
      "I0319 16:03:42.482314 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 16.32s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0319 16:03:42.502212 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0319 16:03:42.504222 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0319 16:03:42.504222 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0319 16:03:42.506317 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0319 16:03:42.507338 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0319 16:03:42.507338 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0319 16:03:42.508344 29368 test_util.py:2460] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 20.741s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# This line creates a string variable that holds the path to the verification script\n",
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "\n",
    "# This line runs the verification script to check that the TensorFlow Object Detection API was installed correctly\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install any packages that are missing or use packages that are suitable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import object detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download Pretrained model archieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) moved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "# This block of code downloads and extracts the pretrained model archive\n",
    "if os.name =='posix':\n",
    "    # If the operating system is POSIX (e.g. Linux or MacOS), download and extract the archive using `wget` and `tar`\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    # If the operating system is Windows, download and extract the archive using `wget.download` and `tar`\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Create Label Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}, {'name':'ThumbsDown', 'id':2}, {'name':'ThankYou', 'id':3}, {'name':'LiveLong', 'id':4}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\scripts'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow\\workspace\\images\\train\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(paths['IMAGE_PATH'], 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n",
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(paths['ANNOTATION_PATH'], 'train.record'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Copy Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.0 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install any missing modules if error occurs \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gin-config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.0 Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Detect from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.0 Real time detections from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.0 Freezing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.0 Conversion to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.0 Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.0 Zip and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-c-tfod-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
